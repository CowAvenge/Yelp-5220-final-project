{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/eitan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from num2words import num2words  # Converting numbers to word form\n",
    "import ijson  # Parser for large json files\n",
    "import csv\n",
    "\n",
    "import nltk  # Import nltk module\n",
    "from nltk.corpus import stopwords  # Stop word dictionary\n",
    "from nltk.stem import PorterStemmer  # Stems words\n",
    "from nltk.tokenize import word_tokenize  # Tokenizer\n",
    "\n",
    "# Download stopwords dictionary\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"yelp_academic_dataset_review.json\"\n",
    "\n",
    "# Example of a json object in the review file:\n",
    "# {\"review_id\":\"btHrA_nXUceLqZRvymvXng\",\"user_id\":\"amaOELCfgLup2MwE2j8PfA\",\"business_id\":\"_v3DcLatG70adfYzWTd-CQ\",\"stars\":5.0,\"useful\":2,\"funny\":2,\"cool\":1,\"text\":\"I love this store!\",\"date\":\"2015-03-18 21:09:07\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cleaning/preprocessing function\n",
    "def text_preprocess(text):\n",
    "    '''\n",
    "    Function: Process takes an incoming JSON text review and preprocesses it by:\n",
    "    1. converting string to lowercase\n",
    "    2. removing stop words (is, it, a, but etc)\n",
    "    3. converts numbers to their word form (1 -> one) NOTE: Unclear if this is neccessary, but was suggsted online\n",
    "    4. Stem the words (convert words like programming -> program)\n",
    "    \n",
    "    Input: JSON item \"review\"\n",
    "    Output: preprocessed string\n",
    "    '''\n",
    "    # Define array to store processed words:\n",
    "    processed_words = []\n",
    "\n",
    "    # Define stop_words dict using nltk package\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Split string into list\n",
    "    split = text.split()\n",
    "    \n",
    "    # Create stemmer object\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    # Iterate through each word\n",
    "    for word in split:\n",
    "        # Convert word to lowercase\n",
    "        word = word.lower()\n",
    "\n",
    "        # Check if word is a stop word before proceeding\n",
    "        if word in stop_words:\n",
    "            continue # Continue will skip current iteration (current word) if it is a stop word\n",
    "        \n",
    "        if word == 'infinity': # Edgecase check if word is infinity, as num2words does not handle it correctly\n",
    "            processed_words.append('infinity')\n",
    "            continue # Continue to next word\n",
    "\n",
    "        # Convert numbers to word form \n",
    "        try:\n",
    "            # Check if word is a number\n",
    "            float(word)  # This will raise ValueError if the word is not a number\n",
    "            word = num2words(word)\n",
    "        except ValueError:\n",
    "            # If it's not a number, we can stem the word\n",
    "            word = ps.stem(word)\n",
    "        \n",
    "        processed_words.append(word)\n",
    "\n",
    "    # Join the processed words to form a clean text\n",
    "    clean_text = ' '.join(processed_words)\n",
    "\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/eitan/Documents/Supervised ML/FInal Project/JSON_preprocessing.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m text \u001b[39m=\u001b[39m review[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# date = review['date']\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# useful = review['useful']\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# funny = review['funny']\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# cool = review['cool']\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m processed_text \u001b[39m=\u001b[39m text_preprocess(text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Write the data to the CSV file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m csv_writer\u001b[39m.\u001b[39mwriterow([stars, processed_text])\n",
      "\u001b[1;32m/Users/eitan/Documents/Supervised ML/FInal Project/JSON_preprocessing.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m# Check if word is a number\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mfloat\u001b[39m(word)  \u001b[39m# This will raise ValueError if the word is not a number\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     word \u001b[39m=\u001b[39m num2words(word)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39m# If it's not a number, we can stem the word\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eitan/Documents/Supervised%20ML/FInal%20Project/JSON_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     word \u001b[39m=\u001b[39m ps\u001b[39m.\u001b[39mstem(word)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/num2words/__init__.py:104\u001b[0m, in \u001b[0;36mnum2words\u001b[0;34m(number, ordinal, lang, to, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m to \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m CONVERTES_TYPES:\n\u001b[1;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m()\n\u001b[0;32m--> 104\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(converter, \u001b[39m'\u001b[39;49m\u001b[39mto_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(to))(number, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/num2words/base.py:117\u001b[0m, in \u001b[0;36mNum2Word_Base.to_cardinal\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m value \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMAXVAL:\n\u001b[1;32m    115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOverflowError\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrmsg_toobig \u001b[39m%\u001b[39m (value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMAXVAL))\n\u001b[0;32m--> 117\u001b[0m val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplitnum(value)\n\u001b[1;32m    118\u001b[0m words, num \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclean(val)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtitle(out \u001b[39m+\u001b[39m words)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/num2words/base.py:89\u001b[0m, in \u001b[0;36mNum2Word_Base.splitnum\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     86\u001b[0m out\u001b[39m.\u001b[39mappend((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcards[elem], elem))\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m mod:\n\u001b[0;32m---> 89\u001b[0m     out\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplitnum(mod))\n\u001b[1;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/num2words/base.py:71\u001b[0m, in \u001b[0;36mNum2Word_Base.splitnum\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcards:\n\u001b[1;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m elem \u001b[39m>\u001b[39m value:\n\u001b[0;32m---> 71\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     out \u001b[39m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Open the JSON file and CSV file\n",
    "input_file = file_name  # Replace with your actual file path\n",
    "output_file = 'processed_reviews.csv'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as json_file, open(output_file, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    # Write the CSV header\n",
    "    csv_writer.writerow(['review_id', 'user_id', 'business_id', 'stars', 'text', 'date'])\n",
    "    \n",
    "    # Parse each line in the JSON file as a separate JSON object\n",
    "    for line in json_file:\n",
    "        review = eval(line.strip())  # Convert string to dictionary\n",
    "        if isinstance(review, dict):  # Ensure it's a valid JSON object\n",
    "            # Extract all fields from the JSON object\n",
    "\n",
    "            # NOTE: I commented out features we aren't using at this time. Only stars and text remain (eitan)\n",
    "            \n",
    "            # review_id = review['review_id']\n",
    "            # user_id = review['user_id']\n",
    "            # business_id = review['business_id']\n",
    "            stars = review['stars']\n",
    "            text = review['text']\n",
    "            # date = review['date']\n",
    "            # useful = review['useful']\n",
    "            # funny = review['funny']\n",
    "            # cool = review['cool']\n",
    "            processed_text = text_preprocess(text)\n",
    "            \n",
    "            # Write the data to the CSV file\n",
    "            csv_writer.writerow([stars, processed_text])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
